import hashlib
import os

def find_duplicates(path):
    hashes = {}
    duplicates = []
    for root, dirs, files in os.walk(path):
        for file in files:
            file_path = os.path.join(root, file)
            with open(file_path, "rb") as f:
                file_hash = hashlib.md5(f.read()).hexdigest()
                if file_hash in hashes:
                    duplicates.append((file_path, hashes[file_hash]))
                else:
                    hashes[file_hash] = file_path
    return duplicates

def remove_duplicates(duplicates):
    for duplicate in duplicates:
        os.remove(duplicate[0])

if __name__ == "__main__":
    path = input("Enter the path to the directory: ")
    duplicates = find_duplicates(path)
    remove_duplicates(duplicates)
    print("Duplicates removed.")
